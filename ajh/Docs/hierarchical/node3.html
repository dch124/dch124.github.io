<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 3.0//EN">
<!--Converted with LaTeX2HTML 96.1-f (May 31, 1996) by Nikos Drakos (nikos@cbl.leeds.ac.uk), CBLU, University of Leeds -->
<HTML>
<HEAD>
<TITLE>3 A Hierarchical PDM</TITLE>
<META NAME="description" CONTENT="3 A Hierarchical PDM">
<META NAME="keywords" CONTENT="hpaper">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">
<LINK REL=STYLESHEET HREF="hpaper.css">
</HEAD>
<BODY LANG="EN">
 <A NAME="tex2html50" HREF="node4.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="http://cbl.leeds.ac.uk/nikos/figs/next_motif.gif"></A> <A NAME="tex2html48" HREF="hpaper.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="http://cbl.leeds.ac.uk/nikos/figs/up_motif.gif"></A> <A NAME="tex2html42" HREF="node2.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="http://cbl.leeds.ac.uk/nikos/figs/previous_motif.gif"></A>   <BR>
<B> Next:</B> <A NAME="tex2html51" HREF="node4.html">4 Evaluation</A>
<B>Up:</B> <A NAME="tex2html49" HREF="hpaper.html">Improving Specificity in PDMs  </A>
<B> Previous:</B> <A NAME="tex2html43" HREF="node2.html">2 The Point Distribution </A>
<BR> <P>
<H1><A NAME="SECTION00030000000000000000">3 A Hierarchical PDM</A></H1>
<P>
Bregler and Omohundro&nbsp;[<A HREF="node6.html#bregler94">2</A>] describe a solution to this
problem, whereby a constraint surface is constructed within 
shape space, using a union of lower dimensional subspaces.
We have altered and extended this technique by considering a
two-level hierarchical approach, and by substituting the hyperplane
subspaces for bounded regions.
<P>
The key to the approach is that a complex, non-linear region
approaches linearity locally under magnification, and hence can be
approximated by a combination of a number of smaller linear subregions.
To build the subregions, a <I>k</I>-means cluster analysis is performed
on the training data in shape space to find a number of prototypes. For
each prototype, a number of nearest neighbours are taken from the
training set and a PCA is performed on them. A subregion is produced
which is 
centred on the cluster mean (<em>not</em>
necessarily the same as the prototype),
and bounded by a hyperellipsoid with a
Malhalanobis radius of some
specified value <I>M</I> (similar to a standard Linear PDM).
The VSR is then represented
as the union of these subregions
(there are some subtleties; these are discussed
later). Figure&nbsp;<A HREF="node3.html#shapespace">1</A> demonstrates the process.
<P>
<P><A NAME="76">&#160;</A><A NAME="shapespace">&#160;</A> <IMG WIDTH=617 HEIGHT=155 ALIGN=BOTTOM ALT="figure73" SRC="img11.gif"  > <BR>
<STRONG>Figure 1:</STRONG> Building a valid shape region
from linear patches; (a) training data projected into a 2D shape
space,
(b) <I>k</I>-means cluster
centres, (c) principal axes and (d) the valid shape region.<BR>
<P>
<P>
In the case of the PDM, the shape space generally has upwards of
100 dimensions (twice the number of model
landmark points).
For this reason it is useful to adopt 
a two-level hierarchical approach;
an initial <em>global</em> PCA is performed on the training data in order to
produce a lower dimensional space.
The linear subregions are then constructed in this new space
instead of the high dimensional shape space.
The reduced dimensionality decreases computation times substantially,
and noise from outliers
is reduced due to the removal of insignificant modes of
variation by the global PCA.
<P>
For the VSR to be of practical use, it must be possible to apply
what is known as the `nearest point' query: ``Given a general point
in shape space, where is the nearest point in the VSR?'' This
then facilitates the application of constraints to any given shape.
<P>
The simplest (but not only) way to apply these constraints
is to find the closest (Euclidian distance) cluster mean and
constrain the point to be within the associated subregion.
The point should ideally be moved to the <em>closest</em> position within the
subregion (hyperellipsoid-bounded), however this requires an expensive
gradient descent computation, and instead we approximate the subregion
as a hypercuboid. The alternative of 
moving the point directly towards the cluster mean is grossly
inaccurate for eccentric hyperellipsoids.
Figure&nbsp;<A HREF="node3.html#constraining">2</A> illustrates.
<P>
<P><A NAME="85">&#160;</A><A NAME="constraining">&#160;</A> <IMG WIDTH=618 HEIGHT=114 ALIGN=BOTTOM ALT="figure82" SRC="img12.gif"  > <BR>
<STRONG>Figure 2:</STRONG> Constraining a general point to lie within a linear subregion;
(a) the correct way, (b) a bad approximate method and (c) a better
approximate method.<BR>
<P>
<P>
There are other ways to apply the constraints;
Bregler describes a constraint function <I>C</I> on a shape  <IMG WIDTH=9 HEIGHT=7 ALIGN=BOTTOM ALT="tex2html_wrap_inline483" SRC="img13.gif"  >  as follows:
<P>
<P> <IMG WIDTH=361 HEIGHT=39 ALIGN=BOTTOM ALT="equation89" SRC="img14.gif"  > <P>
<P>
where  <IMG WIDTH=36 HEIGHT=16 ALIGN=BOTTOM ALT="tex2html_wrap_inline485" SRC="img15.gif"  >  is the
shape  <IMG WIDTH=9 HEIGHT=7 ALIGN=BOTTOM ALT="tex2html_wrap_inline487" SRC="img16.gif"  >  as projected into the subregion of cluster <I>i</I> and
 <IMG WIDTH=16 HEIGHT=13 ALIGN=BOTTOM ALT="tex2html_wrap_inline491" SRC="img17.gif"  >  is the <em>influence</em> function for cluster <I>i</I>. Setting  <IMG WIDTH=46 HEIGHT=13 ALIGN=BOTTOM ALT="tex2html_wrap_inline495" SRC="img18.gif"  >  if cluster <I>i</I> is closest and  <IMG WIDTH=46 HEIGHT=13 ALIGN=BOTTOM ALT="tex2html_wrap_inline499" SRC="img19.gif"  >  if not results in the
simple algorithm described above. Alternatively,  <IMG WIDTH=16 HEIGHT=13 ALIGN=BOTTOM ALT="tex2html_wrap_inline501" SRC="img20.gif"  >  can be a
Gaussian, centred on cluster <I>i</I>'s mean:
<P>
<P> <IMG WIDTH=372 HEIGHT=40 ALIGN=BOTTOM ALT="equation98" SRC="img21.gif"  > <P>
<P>
where  <IMG WIDTH=14 HEIGHT=11 ALIGN=BOTTOM ALT="tex2html_wrap_inline505" SRC="img22.gif"  >  is the cluster mean and  <IMG WIDTH=13 HEIGHT=13 ALIGN=BOTTOM ALT="tex2html_wrap_inline507" SRC="img23.gif"  >  is a scale
factor related to the `size' of cluster <I>i</I>. A
sensible value for  <IMG WIDTH=13 HEIGHT=13 ALIGN=BOTTOM ALT="tex2html_wrap_inline511" SRC="img24.gif"  >  is the square root of the sum of the
eigenvalues from the local PCA. It is important to note that in the above
equation, the <em>Euclidian</em> distance (as opposed to the
Malhalanobis distance) is used; otherwise the influence function decays
too quickly off-axis for eccentric hyperellipsoids.
<P>
For a particular  <IMG WIDTH=9 HEIGHT=7 ALIGN=BOTTOM ALT="tex2html_wrap_inline513" SRC="img25.gif"  > ,  <IMG WIDTH=38 HEIGHT=16 ALIGN=BOTTOM ALT="tex2html_wrap_inline515" SRC="img26.gif"  >  will be very small
for the majority of <I>i</I>. The calculation of  <IMG WIDTH=33 HEIGHT=16 ALIGN=BOTTOM ALT="tex2html_wrap_inline519" SRC="img27.gif"  >  can be
made more efficient by only including terms for which
 <IMG WIDTH=38 HEIGHT=16 ALIGN=BOTTOM ALT="tex2html_wrap_inline521" SRC="img28.gif"  >  is significant. A cutoff point of one
tenth of the maximum value is suitable.
<P>
Using the Gaussian influence functions has the effect of performing an
interpolation at positions between neighbouring clusters, giving
smoother joins, especially in cases where the subregions don't actually
overlap.
However, a side effect is that
the notion of a concrete divide between valid and invalid shapes is
lost, insofar as that if  <IMG WIDTH=68 HEIGHT=16 ALIGN=BOTTOM ALT="tex2html_wrap_inline523" SRC="img29.gif"  >  then it is not
necessarily the case that
 <IMG WIDTH=72 HEIGHT=16 ALIGN=BOTTOM ALT="tex2html_wrap_inline525" SRC="img30.gif"  > . It is thus
important to only apply the constraint function <em>once</em> each time
the shape needs constraining. Also this method is slower than the
nearest-cluster method.
<P>
The method we describe here is based on
Bregler and Omohundro's approach, but differs in 
two aspects. Firstly, they treated the linear patches as
lower-dimensional hyperplanes,
whereas we prefer to use hyperellipsoid-bounded regions.
The hyperplanes method has
the undesirable property that it extends the VSR
indefinitely at extremities (see Figure&nbsp;<A HREF="node3.html#extremities">3</A>). Secondly,
we have introduced the idea of a hierarchical framework, whereby a
global PCA is performed prior to
the constraint process. This increases efficiency and also removes some
training data noise.
<P>
An alternative approach is described in the statistics literature.
The VSR can be modelled as a
probability density function, approximated as a Gaussian
mixture. Instead of using <I>k</I>-means to determine the Gaussians, the EM
algorithm&nbsp;[<A HREF="node6.html#dempster77">4</A>] can be used with equal, if not better,
success.
<P>
<P><A NAME="120">&#160;</A><A NAME="extremities">&#160;</A> <IMG WIDTH=615 HEIGHT=173 ALIGN=BOTTOM ALT="figure117" SRC="img31.gif"  > <BR>
<STRONG>Figure 3:</STRONG> Constraining shape using (a) hyperplanes and (b) hyperellipsoids.<BR>
<P><H2><A NAME="SECTION00031000000000000000">Choosing <I>k</I>, the  and <I>M</I></A></H2>
<P>
<I>k</I> is the number of clusters that are used to build the
VSR.  <IMG WIDTH=13 HEIGHT=9 ALIGN=BOTTOM ALT="tex2html_wrap_inline543" SRC="img32.gif"  >  is the number of nearest-neighbour
training examples used to build the linear
subregion for cluster <I>i</I>.
Between them, <I>k</I> and the  <IMG WIDTH=13 HEIGHT=9 ALIGN=BOTTOM ALT="tex2html_wrap_inline549" SRC="img33.gif"  >  determine the degree of cluster
overlap.
<P>
Our current strategy is to specify a <em>fixed</em>
degree of cluster overlap, <I>O</I>,
and set  <IMG WIDTH=13 HEIGHT=9 ALIGN=BOTTOM ALT="tex2html_wrap_inline553" SRC="img34.gif"  > , where  <IMG WIDTH=59 HEIGHT=13 ALIGN=BOTTOM ALT="tex2html_wrap_inline555" SRC="img35.gif"  >  is the number of members in the
<I>k</I>-means cluster. The argument for overlap is that it results in
smoother transitions between subregions.
Initial experimentation suggests that <I>O</I> = 1.5 produces a good
balance between accuracy (allowing all valid shapes) and specificity
(disallowing invalid shapes).
<P>
The choice of <I>k</I> is data-dependent. The more complex and non-linear
the VSR, the larger the number of clusters required to
model it accurately; however, there is a trade-off between accuracy and
speed. If speed is not an issue then <I>k</I> can be increased in the limit
to <I>E</I> (but the choice of <I>O</I> must be reconsidered).
For noiseless training data this produces the smoothest model; however
any noise that <em>is</em> present is liable to be included in the
model.
<P>
So far we have chosen <I>k</I> manually, based on knowledge about
the expected shape of the VSR. It seems likely that it
would be possible to find a sensible value for <I>k</I> automatically
via some optimisation technique. If unsure, a good first guess would be
<I>k</I> = <I>E</I> / 10.
<P>
Also important is the choice of <I>M</I>--the Malhalanobis radius of the
clusters. We have chosen <I>M</I>=2.0 which, statistically, encompasses
over 95% of the cluster members.
A larger value generally leads an underconstrained shape space.
<P>
<HR><A NAME="tex2html50" HREF="node4.html"><IMG WIDTH=37 HEIGHT=24 ALIGN=BOTTOM ALT="next" SRC="http://cbl.leeds.ac.uk/nikos/figs/next_motif.gif"></A> <A NAME="tex2html48" HREF="hpaper.html"><IMG WIDTH=26 HEIGHT=24 ALIGN=BOTTOM ALT="up" SRC="http://cbl.leeds.ac.uk/nikos/figs/up_motif.gif"></A> <A NAME="tex2html42" HREF="node2.html"><IMG WIDTH=63 HEIGHT=24 ALIGN=BOTTOM ALT="previous" SRC="http://cbl.leeds.ac.uk/nikos/figs/previous_motif.gif"></A>   <BR>
<B> Next:</B> <A NAME="tex2html51" HREF="node4.html">4 Evaluation</A>
<B>Up:</B> <A NAME="tex2html49" HREF="hpaper.html">Improving Specificity in PDMs  </A>
<B> Previous:</B> <A NAME="tex2html43" HREF="node2.html">2 The Point Distribution </A>
<P><ADDRESS>
<I>A J Heap <BR>
Wed Jul  2 14:34:50 BST 1997</I>
</ADDRESS>
</BODY>
</HTML>
